{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example usage of VI with a PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.3.0\r\n",
      "anyio @ file:///tmp/build/80754af9/anyio_1644463572971/work/dist\r\n",
      "aqtp==0.0.10\r\n",
      "argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\r\n",
      "argon2-cffi-bindings @ file:///tmp/build/80754af9/argon2-cffi-bindings_1644569679365/work\r\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\r\n",
      "astunparse==1.6.3\r\n",
      "attrs @ file:///croot/attrs_1668696182826/work\r\n",
      "Babel @ file:///tmp/build/80754af9/babel_1620871417480/work\r\n",
      "backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\r\n",
      "beautifulsoup4 @ file:///opt/conda/conda-bld/beautifulsoup4_1650462163268/work\r\n",
      "bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work\r\n",
      "brotlipy==0.7.0\r\n",
      "cached-property==1.5.2\r\n",
      "cachetools==5.2.0\r\n",
      "certifi @ file:///croot/certifi_1671487769961/work/certifi\r\n",
      "cffi @ file:///tmp/abs_98z5h56wf8/croots/recipe/cffi_1659598650955/work\r\n",
      "charset-normalizer==2.1.1\r\n",
      "chex==0.1.5\r\n",
      "cloudpickle==2.2.0\r\n",
      "clu==0.0.7\r\n",
      "commonmark==0.9.1\r\n",
      "contextlib2==21.6.0\r\n",
      "contourpy==1.0.6\r\n",
      "cryptography @ file:///croot/cryptography_1665612644927/work\r\n",
      "cycler==0.11.0\r\n",
      "dacite==1.6.0\r\n",
      "debugpy @ file:///tmp/build/80754af9/debugpy_1637091799509/work\r\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\r\n",
      "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\r\n",
      "dill==0.3.6\r\n",
      "dm-tree==0.1.7\r\n",
      "einops==0.6.0\r\n",
      "entrypoints @ file:///tmp/build/80754af9/entrypoints_1649926439650/work\r\n",
      "etils==0.9.0\r\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\r\n",
      "fastjsonschema @ file:///opt/conda/conda-bld/python-fastjsonschema_1661371079312/work\r\n",
      "flatbuffers==22.11.23\r\n",
      "flax==0.6.2\r\n",
      "flaxformer @ git+https://github.com/google/flaxformer@85d341174c83743a4e4179db33f32840df9918cc\r\n",
      "flit_core @ file:///opt/conda/conda-bld/flit-core_1644941570762/work/source/flit_core\r\n",
      "fonttools==4.38.0\r\n",
      "gast==0.4.0\r\n",
      "google-auth==2.15.0\r\n",
      "google-auth-oauthlib==0.4.6\r\n",
      "google-pasta==0.2.0\r\n",
      "googleapis-common-protos==1.57.0\r\n",
      "grpcio==1.51.1\r\n",
      "h5py==3.7.0\r\n",
      "idna @ file:///croot/idna_1666125576474/work\r\n",
      "importlib-metadata==5.1.0\r\n",
      "importlib-resources==5.10.0\r\n",
      "ipykernel @ file:///opt/conda/conda-bld/ipykernel_1662361798230/work\r\n",
      "ipython @ file:///croot/ipython_1668088122043/work\r\n",
      "ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\r\n",
      "ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1634143127070/work\r\n",
      "jax==0.3.25\r\n",
      "jaxlib==0.3.25\r\n",
      "jedi @ file:///tmp/build/80754af9/jedi_1644297102865/work\r\n",
      "Jinja2 @ file:///croot/jinja2_1666908132255/work\r\n",
      "json5 @ file:///tmp/build/80754af9/json5_1624432770122/work\r\n",
      "jsonschema @ file:///opt/conda/conda-bld/jsonschema_1663375472438/work\r\n",
      "jupyter @ file:///tmp/abs_33h4eoipez/croots/recipe/jupyter_1659349046347/work\r\n",
      "jupyter-console @ file:///opt/conda/conda-bld/jupyter_console_1647002188872/work\r\n",
      "jupyter-server @ file:///tmp/abs_b88b31b8-83b9-476d-a46d-e563c421f38fvsnyi1ur/croots/recipe/jupyter_server_1658754481507/work\r\n",
      "jupyter_client @ file:///croot/jupyter_client_1669040270237/work\r\n",
      "jupyter_core @ file:///croot/jupyter_core_1668084443243/work\r\n",
      "jupyterlab @ file:///croot/jupyterlab_1669368457990/work\r\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\r\n",
      "jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/work\r\n",
      "jupyterlab_server @ file:///croot/jupyterlab_server_1669363704149/work\r\n",
      "keras==2.11.0\r\n",
      "kiwisolver==1.4.4\r\n",
      "libclang==14.0.6\r\n",
      "lxml @ file:///opt/conda/conda-bld/lxml_1657545139709/work\r\n",
      "Markdown==3.4.1\r\n",
      "MarkupSafe @ file:///opt/conda/conda-bld/markupsafe_1654597864307/work\r\n",
      "matplotlib==3.6.2\r\n",
      "matplotlib-inline @ file:///opt/conda/conda-bld/matplotlib-inline_1662014470464/work\r\n",
      "mistune @ file:///tmp/build/80754af9/mistune_1607364877025/work\r\n",
      "mkl-fft==1.3.1\r\n",
      "mkl-random @ file:///tmp/build/80754af9/mkl_random_1626186066731/work\r\n",
      "mkl-service==2.4.0\r\n",
      "ml-collections==0.1.1\r\n",
      "msgpack==1.0.4\r\n",
      "nbclassic @ file:///croot/nbclassic_1668174957779/work\r\n",
      "nbclient @ file:///tmp/build/80754af9/nbclient_1650290509967/work\r\n",
      "nbconvert @ file:///croot/nbconvert_1668450669124/work\r\n",
      "nbformat @ file:///opt/conda/conda-bld/nbformat_1663744952973/work\r\n",
      "nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1649847906199/work\r\n",
      "notebook @ file:///croot/notebook_1668179881751/work\r\n",
      "notebook_shim @ file:///croot/notebook-shim_1668160579331/work\r\n",
      "numpy @ file:///croot/numpy_and_numpy_base_1672336185480/work\r\n",
      "oauthlib==3.2.2\r\n",
      "opt-einsum==3.3.0\r\n",
      "optax==0.1.4\r\n",
      "packaging @ file:///tmp/build/80754af9/packaging_1637314298585/work\r\n",
      "pandas==1.5.2\r\n",
      "pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work\r\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\r\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\r\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\r\n",
      "Pillow==9.3.0\r\n",
      "ply==3.11\r\n",
      "prometheus-client @ file:///tmp/abs_d3zeliano1/croots/recipe/prometheus_client_1659455100375/work\r\n",
      "promise==2.3\r\n",
      "prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1633440160888/work\r\n",
      "protobuf==3.19.6\r\n",
      "psutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work\r\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\r\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\r\n",
      "pydevd-pycharm==212.5457.59\r\n",
      "Pygments==2.13.0\r\n",
      "pyOpenSSL @ file:///opt/conda/conda-bld/pyopenssl_1643788558760/work\r\n",
      "pyparsing @ file:///opt/conda/conda-bld/pyparsing_1661452539315/work\r\n",
      "PyQt5-sip==12.11.0\r\n",
      "pyrsistent @ file:///tmp/build/80754af9/pyrsistent_1636110951836/work\r\n",
      "PySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work\r\n",
      "python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\r\n",
      "pytz==2022.6\r\n",
      "PyYAML==6.0\r\n",
      "pyzmq @ file:///opt/conda/conda-bld/pyzmq_1657724186960/work\r\n",
      "qtconsole @ file:///opt/conda/conda-bld/qtconsole_1662018252641/work\r\n",
      "QtPy @ file:///opt/conda/conda-bld/qtpy_1662014892439/work\r\n",
      "requests @ file:///opt/conda/conda-bld/requests_1657734628632/work\r\n",
      "requests-oauthlib==1.3.1\r\n",
      "rich==12.6.0\r\n",
      "rsa==4.9\r\n",
      "scipy==1.9.3\r\n",
      "Send2Trash @ file:///tmp/build/80754af9/send2trash_1632406701022/work\r\n",
      "sip @ file:///tmp/abs_44cd77b_pu/croots/recipe/sip_1659012365470/work\r\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\r\n",
      "sniffio @ file:///tmp/build/80754af9/sniffio_1614030464178/work\r\n",
      "soupsieve @ file:///croot/soupsieve_1666296392845/work\r\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\r\n",
      "tensorboard==2.11.0\r\n",
      "tensorboard-data-server==0.6.1\r\n",
      "tensorboard-plugin-wit==1.8.1\r\n",
      "tensorflow==2.11.0\r\n",
      "tensorflow-cpu==2.11.0\r\n",
      "tensorflow-datasets==4.7.0\r\n",
      "tensorflow-estimator==2.11.0\r\n",
      "tensorflow-hub==0.12.0\r\n",
      "tensorflow-io-gcs-filesystem==0.28.0\r\n",
      "tensorflow-metadata==1.11.0\r\n",
      "tensorflow-probability==0.18.0\r\n",
      "tensorflow-text==2.11.0\r\n",
      "tensorstore==0.1.28\r\n",
      "termcolor==2.1.1\r\n",
      "terminado @ file:///tmp/build/80754af9/terminado_1644322582718/work\r\n",
      "tinycss2 @ file:///croot/tinycss2_1668168815555/work\r\n",
      "toml @ file:///tmp/build/80754af9/toml_1616166611790/work\r\n",
      "tomli @ file:///opt/conda/conda-bld/tomli_1657175507142/work\r\n",
      "toolz==0.12.0\r\n",
      "torch==1.13.1\r\n",
      "torchvision==0.14.1\r\n",
      "tornado @ file:///opt/conda/conda-bld/tornado_1662061693373/work\r\n",
      "tqdm==4.64.1\r\n",
      "traitlets @ file:///tmp/build/80754af9/traitlets_1636710298902/work\r\n",
      "typing_extensions @ file:///croot/typing_extensions_1669924550328/work\r\n",
      "urllib3==1.26.13\r\n",
      "vit-inspect @ git+https://github.com/stamatiad/vit_inspect.git@a7c73af6076848b24250b5f9cfda8c5bf4461931\r\n",
      "watermark==2.3.1\r\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client @ file:///tmp/build/80754af9/websocket-client_1614803975924/work\r\n",
      "Werkzeug==2.2.2\r\n",
      "widgetsnbextension @ file:///tmp/build/80754af9/widgetsnbextension_1644992802045/work\r\n",
      "wrapt==1.14.1\r\n",
      "zipp==3.11.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clone the repo of the model and checkout our customized branch to see\n",
    "the changes required by the VI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/stamatiad/dino.git\n",
    "%cd dino\n",
    "!git checkout stamatiad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have created a wrapper function (save_attn_weights) that\n",
    "wraps the forward method of Attention. Now each time the forward method is\n",
    "called and we have VI recording enabled (with vi.enable_vi() context manager)\n",
    ", we will save the TB summaries in the directory ./vi_logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git diff main..stamatiad -- vision_transformer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have installed the required python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happened to have issues with packages' versions and you restarted your\n",
    "runtime, make sure you are in the right folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on the original DINO with PyTorch:\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as pth_transforms\n",
    "from vision_transformer import VisionTransformer\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# VI imports:\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from vit_inspect import vit_inspector as vi\n",
    "from vit_inspect.summary_v2 import vi_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained model and transfer its parameters to a new instance of\n",
    "our modified model, that VI listens to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model:\n",
    "model_cached = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "# Create a version of the model that holds our attention VI modifications:\n",
    "# Match model params, before load:\n",
    "num_features = model_cached.embed_dim\n",
    "model = VisionTransformer(embed_dim=num_features)\n",
    "model.load_state_dict(model_cached.state_dict(), strict=False)\n",
    "\n",
    "# Enable evaluation mode:\n",
    "device = torch.device(\"cpu\")\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the VI and inform it about our model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some model params, required for VI:\n",
    "vi.params[\"num_layers\"] = len(model.blocks)\n",
    "vi.params[\"num_heads\"] = model.blocks[0].attn.num_heads\n",
    "# The number of tokens when the attention dot product happens.\n",
    "# Here tokens are the patches. Any other feature (e.g. class) is removed.\n",
    "patch_size = model.patch_embed.patch_size\n",
    "crop_size = 480\n",
    "img_size_in_patches = crop_size // patch_size\n",
    "vi.params[\"len_in_patches\"] = img_size_in_patches\n",
    "# Total patches in the image:\n",
    "vi.params[\"num_tokens\"] = img_size_in_patches ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a sample image to calculate attention maps uppon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images:\n",
    "response = requests.get(\"https://dl.fbaipublicfiles.com/dino/img.png\")\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.convert('RGB')\n",
    "\n",
    "# Perform the original transformations that the authors did.\n",
    "transform = pth_transforms.Compose([\n",
    "    pth_transforms.Resize(img.size),\n",
    "    pth_transforms.ToTensor(),\n",
    "    pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "img = transform(img)\n",
    "# make the image divisible by the patch size\n",
    "w, h = img.shape[1] - img.shape[1] % patch_size, \\\n",
    "       img.shape[2] - img.shape[2] % patch_size\n",
    "img = img[:, :w, :h].unsqueeze(0)\n",
    "\n",
    "w_featmap = img.shape[-2] // patch_size\n",
    "h_featmap = img.shape[-1] // patch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the input image for the VI to display it as preview, making it\n",
    " easier to visualize the attention maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the input image into the summary:\n",
    "flat_arr_rgb = tf.convert_to_tensor(\n",
    "    # Make sure image's channels is the last dim:\n",
    "    np.moveaxis(np.asarray(img), 1, -1)\n",
    ")\n",
    "with vi.writer.as_default():\n",
    "    step = 0\n",
    "    batch_id = 0\n",
    "    vi.params[\"step\"] = 0\n",
    "    vi.params[\"batch_id\"] = batch_id\n",
    "    vi_summary(\n",
    "        f\"b{batch_id}\",\n",
    "        flat_arr_rgb,\n",
    "        step=step,\n",
    "        description=json.dumps(vi.params)\n",
    "    )\n",
    "    vi.writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, perform inference with VI enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the VI context manager to get attention maps of each layer and head:\n",
    "with vi.enable_vi():\n",
    "    attentions = model.get_last_selfattention(img.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir vi_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
